# Database Configuration (SQLite for free local setup)
DATABASE_URL=sqlite:///./llm_api.db

# LLM Configuration (llama.cpp: CPU-only, free)
LLM_PROVIDER=llamacpp
# Path to a local GGUF model (download separately). Example uses TinyLlama to keep it small.
LLM_MODEL_PATH=models/TinyLlama-1.1B-Chat-v1.0.Q4_K_M.gguf
LLM_CONTEXT_SIZE=4096
LLM_N_GPU_LAYERS=0
# Optional threads override (defaults to auto)
# LLM_THREADS=6

# Security (dev defaults; change in production)
SECRET_KEY=dev-secret-change-me
JWT_SECRET=dev-jwt-secret-change-me
JWT_ALGORITHM=HS256
JWT_EXPIRATION_MINUTES=30

# Rate Limiting
RATE_LIMIT_REQUESTS=100
RATE_LIMIT_WINDOW=3600

# Pricing (0 for free local usage)
PRICE_PER_1K_TOKENS=0.0

# CORS
ALLOWED_ORIGINS=["*"]

# Logging
LOG_LEVEL=INFO

# Application
DEBUG=true
APP_NAME=My Own LLM API
APP_VERSION=1.0.0
